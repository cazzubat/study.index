{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando um Chatbot com IA (Parte 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ O que √© um Chatbot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um chatbot √© um programa de computador que simula uma conversa humana, podendo responder perguntas, fornecer informa√ß√µes e at√© realizar a√ß√µes automatizadas. Ele pode funcionar por texto (ChatGPT ou DeepSeek) ou voz (como a Alexa ou o Google Assistente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Como um Chatbot Funciona?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um chatbot pode funcionar de duas formas principais:\n",
    "\n",
    "1Ô∏è‚É£ Chatbots Baseados em Regras (Simples):\n",
    "Esses bots seguem um conjunto fixo de regras. Eles s√≥ entendem perguntas espec√≠ficas e respondem com respostas pr√©-definidas.\n",
    "\n",
    "‚úÖ Exemplo:\n",
    "- üë§ Usu√°rio: \"Qual o hor√°rio de funcionamento?\"\n",
    "- ü§ñ Bot: \"Nosso hor√°rio √© das 9h √†s 18h, de segunda a sexta.\"\n",
    "\n",
    "üìå Como funciona?\n",
    "\n",
    "Ele verifica se a pergunta corresponde a um padr√£o pr√©-programado.\n",
    "Responde com uma resposta fixa.\n",
    "Desvantagem: Se a pergunta for diferente do esperado, ele pode n√£o entender.\n",
    "\n",
    "2Ô∏è‚É£ Chatbots com Intelig√™ncia Artificial (IA/NLP)\n",
    "Esses bots usam Processamento de Linguagem Natural (NLP) e Machine Learning (ML) para entender frases de forma mais natural.\n",
    "\n",
    "‚úÖ Exemplo:\n",
    "- üë§ Usu√°rio: \"Me fala sobre o hor√°rio de voc√™s?\"\n",
    "- ü§ñ Bot: \"Nosso atendimento √© das 9h √†s 18h de segunda a sexta-feira.\"\n",
    "\n",
    "üìå Como funciona?\n",
    "\n",
    "Ele transforma o texto do usu√°rio em um formato compreens√≠vel.\n",
    "Usa modelos de IA para interpretar o significado.\n",
    "Gera uma resposta din√¢mica com base no contexto.\n",
    "Aprende com intera√ß√µes anteriores para melhorar suas respostas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tecnologias Usadas em Chatbots\n",
    "Chatbots podem ser constru√≠dos com v√°rias tecnologias, como:\n",
    "\n",
    "- üîπ NLP (Processamento de Linguagem Natural) ‚Üí Para entender a linguagem humana (Ex: spaCy, NLTK, Hugging Face).\n",
    "- üîπ Redes Neurais ‚Üí Para respostas mais inteligentes e aprendizado cont√≠nuo (Ex: ChatGPT).\n",
    "- üîπ APIs de IA ‚Üí Como Dialogflow (Google), Watson Assistant (IBM), Microsoft Bot Framework.\n",
    "- üîπ Frameworks para Chatbots ‚Üí Rasa, ChatterBot, BotPress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langchain](langchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå O que √© LangChain e como ele melhora os Chatbots?\n",
    "\n",
    "Vamos aprender a usar o LangChain para criar um sistema de Recupera√ß√£o Aumentada com Gera√ß√£o (RAG), onde um chatbot inteligente responde clientes com base em textos previamente armazenados e uma LLM gratuita.\n",
    "\n",
    "Defini√ß√£o: LangChain √© um framework para construir aplica√ß√µes com Large Language Models (LLMs), como ChatGPT, LLaMA e Mistral.\n",
    "\n",
    "üìå O que √© RAG (Retrieval-Augmented Generation)?\n",
    "\n",
    "Aplica√ß√£o real: Empresas usam RAG para criar agentes de atendimento ao cliente, que interpretam documentos, bases de conhecimento e FAQs.\n",
    "\n",
    "O ChatGPT pode responder com base em conhecimento geral.\n",
    "Um RAG pode responder com base em documentos internos da empresa (exemplo: pol√≠ticas de reembolso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Vis√£o geral das LLMs gratuitas para APIs e locais\n",
    "\n",
    "APIs de LLMs gratuitas:\n",
    "\n",
    "- OpenAI GPT-3.5/GPT-4 (com limites gratuitos).\n",
    "- Mistral e Hugging Face API (modelos open-source).\n",
    "- Together.ai (fornece acesso gratuito a v√°rias LLMs).\n",
    "- Google AI Studio: Disponibiliza modelos de linguagem que podem ser utilizados gratuitamente para diversas aplica√ß√µes. \n",
    "- Hugging Face: Oferece uma ampla gama de modelos de linguagem que podem ser acessados gratuitamente atrav√©s de sua API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RAG](RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![explan](explan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Chamando uma API de LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.20)\n",
      "Collecting openai\n",
      "  Downloading openai-1.68.0-py3-none-any.whl (605 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.47)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.9.0-cp310-cp310-win_amd64.whl (208 kB)\n",
      "Collecting sounddevice>=0.5.1\n",
      "  Downloading sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\cauar\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice>=0.5.1->openai) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.5.1->openai) (2.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Installing collected packages: sounddevice, jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.68.0 sounddevice-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\cauar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauar\\AppData\\Local\\Temp\\ipykernel_13236\\2570343429.py:8: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=api_key)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'openai_api_key': None, ...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Configurando a API da OpenAI (use sua chave de API)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Enviando uma pergunta para a LLM\u001b[39;00m\n\u001b[0;32m     11\u001b[0m resposta \u001b[38;5;241m=\u001b[39m chat([HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComo funciona um chatbot de atendimento ao cliente?\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "File \u001b[1;32mc:\\Users\\cauar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cauar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cauar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'openai_api_key': None, ...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configurando a API da OpenAI (use sua chave de API)\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=api_key)\n",
    "\n",
    "# Enviando uma pergunta para a LLM\n",
    "resposta = chat([HumanMessage(content=\"Como funciona um chatbot de atendimento ao cliente?\")])\n",
    "\n",
    "print(\"Resposta da IA:\", resposta.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.21)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\cauar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.1.0-py3-none-any.whl (40 kB)\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.47)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.18)\n",
      "Collecting filetype<2.0.0,>=1.2.0\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16\n",
      "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
      "Collecting google-auth>=2.15.0\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Collecting google-api-core\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Collecting google-api-python-client\n",
      "  Using cached google_api_python_client-2.165.0-py2.py3-none-any.whl (13.1 MB)\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.2-py3-none-any.whl (153 kB)\n",
      "  Using cached google_generativeai-0.8.1-py3-none-any.whl (165 kB)\n",
      "  Using cached google_generativeai-0.8.0-py3-none-any.whl (163 kB)\n",
      "  Using cached google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "  Using cached google_generativeai-0.7.1-py3-none-any.whl (163 kB)\n",
      "  Using cached google_generativeai-0.7.0-py3-none-any.whl (163 kB)\n",
      "  Using cached google_generativeai-0.6.0-py3-none-any.whl (158 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "  Using cached google_generativeai-0.5.4-py3-none-any.whl (150 kB)\n",
      "  Using cached google_generativeai-0.5.3-py3-none-any.whl (150 kB)\n",
      "  Using cached google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "  Using cached google_generativeai-0.5.1-py3-none-any.whl (142 kB)\n",
      "  Using cached google_generativeai-0.5.0-py3-none-any.whl (142 kB)\n",
      "  Using cached google_generativeai-0.4.1-py3-none-any.whl (137 kB)\n",
      "  Using cached google_generativeai-0.4.0-py3-none-any.whl (137 kB)\n",
      "  Using cached google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
      "  Using cached google_generativeai-0.3.1-py3-none-any.whl (146 kB)\n",
      "  Using cached google_generativeai-0.3.0-py3-none-any.whl (145 kB)\n",
      "  Using cached google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
      "  Using cached google_generativeai-0.2.1-py3-none-any.whl (130 kB)\n",
      "  Using cached google_generativeai-0.2.0-py3-none-any.whl (130 kB)\n",
      "  Using cached google_generativeai-0.1.0-py3-none-any.whl (122 kB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl (39 kB)\n",
      "  Using cached langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\cauar\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: idna in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Collecting httplib2<1.0.0,>=0.19.0\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cauar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Installing collected packages: proto-plus, grpcio, googleapis-common-protos, google-auth, httplib2, grpcio-status, google-api-core, uritemplate, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google-generativeai, filetype, langchain-google-genai\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.165.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 googleapis-common-protos-1.69.2 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 langchain-google-genai-2.0.10 proto-plus-1.26.1 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta da IA: Um chatbot de atendimento ao cliente funciona combinando processamento de linguagem natural (PNL) e intelig√™ncia artificial (IA) para simular uma conversa humana e responder a perguntas e resolver problemas dos clientes.  Seu funcionamento pode ser dividido em etapas principais:\n",
      "\n",
      "**1. Entrada do Usu√°rio:** O cliente interage com o chatbot, geralmente atrav√©s de texto (escrito) ou voz (falado).  A entrada pode ser uma pergunta, um pedido, ou uma declara√ß√£o relacionada a um produto, servi√ßo ou problema.\n",
      "\n",
      "**2. Processamento da Entrada:** O chatbot utiliza PNL para entender a entrada do usu√°rio. Isso envolve:\n",
      "\n",
      "* **Reconhecimento de padr√µes:** Identifica palavras-chave, frases e a inten√ß√£o geral da mensagem do usu√°rio.\n",
      "* **An√°lise de sentimento:** Determina o tom da mensagem (positivo, negativo, neutro) para entender o estado emocional do cliente.\n",
      "* **Extra√ß√£o de entidades:** Identifica informa√ß√µes espec√≠ficas na mensagem, como nomes de produtos, n√∫meros de pedidos, datas, etc.\n",
      "\n",
      "**3. Busca e Sele√ß√£o da Resposta:** Com base na compreens√£o da entrada, o chatbot acessa seu banco de dados de conhecimento. Este banco de dados pode incluir:\n",
      "\n",
      "* **Base de conhecimento:** Um conjunto estruturado de informa√ß√µes sobre produtos, servi√ßos, FAQs e pol√≠ticas da empresa.\n",
      "* **√Årvores de decis√£o:** Fluxo de perguntas e respostas pr√©-definidas para guiar a conversa e resolver problemas comuns.\n",
      "* **Machine Learning (Aprendizado de M√°quina):**  Modelos de IA que aprendem com intera√ß√µes anteriores para melhorar a precis√£o e a efici√™ncia das respostas.  Chatbots mais avan√ßados utilizam aprendizado de m√°quina para gerar respostas mais naturais e contextualizadas.\n",
      "\n",
      "**4. Gera√ß√£o da Resposta:** O chatbot seleciona a melhor resposta com base nas informa√ß√µes processadas.  A resposta pode ser:\n",
      "\n",
      "* **Uma resposta pr√©-definida:** Se a pergunta for comum e houver uma resposta adequada no banco de dados.\n",
      "* **Uma resposta gerada dinamicamente:**  Utilizando t√©cnicas de gera√ß√£o de linguagem natural para criar uma resposta personalizada com base no contexto da conversa.\n",
      "* **Encaminhamento para um agente humano:** Se o chatbot n√£o conseguir entender a pergunta ou resolver o problema.\n",
      "\n",
      "**5. Avalia√ß√£o e Aprendizado (em chatbots mais avan√ßados):** O chatbot pode monitorar a efic√°cia de suas respostas e aprender com as intera√ß√µes.  Isso permite que ele melhore sua capacidade de entender e responder √†s perguntas dos clientes ao longo do tempo.\n",
      "\n",
      "\n",
      "**Tipos de Chatbots:**\n",
      "\n",
      "Existem diferentes tipos de chatbots, com diferentes n√≠veis de sofistica√ß√£o:\n",
      "\n",
      "* **Baseados em regras:** Seguem um conjunto pr√©-definido de regras e fluxos de conversa√ß√£o.\n",
      "* **Baseados em IA:** Utilizam t√©cnicas de aprendizado de m√°quina para aprender com as intera√ß√µes e melhorar suas respostas.\n",
      "* **H√≠bridos:** Combinam regras e IA para oferecer uma experi√™ncia mais eficiente e personalizada.\n",
      "\n",
      "\n",
      "Em resumo, um chatbot de atendimento ao cliente √© uma ferramenta poderosa que automatiza a intera√ß√£o com os clientes, economizando tempo e recursos para as empresas, ao mesmo tempo em que oferece um atendimento mais r√°pido e eficiente aos usu√°rios.  No entanto,  a efic√°cia de um chatbot depende da qualidade do seu banco de dados de conhecimento e da sofistica√ß√£o da sua tecnologia de PNL e IA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "\n",
    "# Configurar a API Key da Gemini (Google AI)\n",
    "api_key = \"AIzaSyAH_6-gFDXEQIm8MuCwvmBUUZJ8AbEgIBo\"\n",
    "\n",
    "# Inicializando o modelo Gemini 1.5 Flash\n",
    "chat = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key)\n",
    "\n",
    "# Enviando uma pergunta para a LLM\n",
    "resposta = chat.invoke(\"Como funciona um chatbot de atendimento ao cliente?\")\n",
    "\n",
    "# Exibir a resposta\n",
    "print(\"Resposta da IA:\", resposta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: Explique o que √© uma IA generativa.\n",
      "\n",
      "A Intelig√™ncia Artificial Generativa (AI Generativa) √© uma subdisciplina da Intelig√™ncia Artificial que utiliza modelos de aprendizagem de m√°quina capazes de gerar informa√ß√µes novas e originais, sem serem direcionados por um humano. Essas informa√ß√µes podem ser texto, imagens, √°udio ou outros formatos de dados.\n",
      "\n",
      "AI Generativas s√£o capazes de analisar e processar grande quantidades de dados existentes e criar novas informa√ß√µes baseadas nesses dados. Eles aprendem a gerar novas informa√ß√µes atrav√©s de algoritmos de aprendizagem profunda, como redes neurais convolucionais (CNNs) e redes recurrentes (RNNs), que podem descobrir padr√µes e estruturas nas informa√ß√µes existentes e usar essas descobertas para gerar novas informa√ß√µes semelhantes.\n",
      "\n",
      "Uma aplica√ß√£o comum de AI Generativas √© a cria√ß√£o de conte√∫do multim√©dia, como imagens, v√≠deos ou textos. Por exemplo, um modelo de AI Generativa pode analisar milhares de imagens de c√£es e ent√£o gerar uma nova imagem de um c√£o que nunca foi visto antes, baseado nos padr√µes e caracter√≠sticas aprendidos dos exemplos existentes. Outra aplica√ß√£o √© a cria√ß√£o de texto, onde o modelo pode analisar milhares de artigos e ent√£o gerar um novo artigo sobre um determinado assunto.\n",
      "\n",
      "Em resumo, uma AI Generativa √© um sistema inteligente capaz de gerar informa√ß√µes novas e originais, sem ser direcionado por um humano, atrav√©s do aprendizado de modelos de m√°quina baseados em grandes quantidades de dados existentes.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "import os\n",
    "\n",
    "\n",
    "# Configurar o modelo da Hugging Face\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",  # Escolha o modelo\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512},  # Configura√ß√µes\n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")  # Usa a API Key\n",
    ")\n",
    "\n",
    "# Testando o modelo\n",
    "resposta = llm.invoke(\"Explique o que √© uma IA generativa.\")\n",
    "print(\"Resposta:\", resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Rodando Modelos LLM Locais com LLaMA e LangChain\n",
    "\n",
    "- Para rodar LLMs no pr√≥prio computador sem depender de APIs.\n",
    "\n",
    "- Instalando o Ollama (para rodar LLaMA localmente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo a passo para isntalar o ollama localmente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acesse o site https://ollama.com\n",
    "- Baixe o instalador de LLMs\n",
    "- Instale na m√°quina\n",
    "- Escolha a LLM que ir√° usar\n",
    "- Instale a LLM no bash do Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' nÔøΩo ÔøΩ reconhecido como um comando interno\n",
      "ou externo, um programa operÔøΩvel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîπ Mistral 7B / Mixtral\n",
    "\n",
    "- Pontos fortes: √ìtimo para conversa√ß√£o e respostas estruturadas.\n",
    "- Onde encontrar: Dispon√≠vel no Ollama (ollama pull mistral).\n",
    "- Ideal para: Chatbots empresariais e suporte t√©cnico.\n",
    "\n",
    "Como usar no LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O Brasil foi descoberto pelos portugueses. Por volta do ano de 1500, a expedi√ß√£o liderada por Pedro √Ålvares Cabral, como parte da frota enviada pelo Rei D. Manuel I de Portugal, desembarcou no atual estado brasileiro de Esp√≠rito Santo, marcando o in√≠cio do processo de coloniza√ß√£o portuguesa do territ√≥rio brasileiro.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Inicializando a LLM local\n",
    "llm = Ollama(model=\"mistral\")\n",
    "resposta = llm(\"Quem descobriu o Brasil?\")\n",
    "print(resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîπ LLaMA 3 (Meta)\n",
    "\n",
    "- Pontos fortes: √ìtima compreens√£o de contexto e menor consumo de mem√≥ria.\n",
    "- Onde encontrar: Dispon√≠vel via Ollama (ollama pull llama3).\n",
    "\n",
    "Como usar no LangChain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Inicializando a LLM local\n",
    "llm = Ollama(model=\"llama3\")\n",
    "resposta = llm(\"O que √© NLP?\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Como Configurar um Chatbot Estruturado com RAG no LangChain\n",
    "\n",
    "Agora, vamos configurar um pipeline de RAG para seu chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: Criando a Base de Conhecimento\n",
    "\n",
    "Agora, vamos configurar um pipeline de RAG para seu chatbot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco de vetores criado com sucesso usando Mistral!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Criando documentos para o FAISS\n",
    "documentos = [\n",
    "    Document(page_content=\"Nosso suporte est√° dispon√≠vel de segunda a sexta, das 9h √†s 18h.\"),\n",
    "    Document(page_content=\"O reembolso pode ser solicitado em at√© 7 dias ap√≥s a compra.\"),\n",
    "    Document(page_content=\"Para falar com um atendente, envie um e-mail para suporte@empresa.com.\"),\n",
    "]\n",
    "\n",
    "# Usando embeddings locais com Ollama (modelo Mistral)\n",
    "vectorstore = FAISS.from_documents(documentos, OllamaEmbeddings(model=\"mistral\"))\n",
    "\n",
    "print(\"Banco de vetores criado com sucesso usando Mistral!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Isso cria um banco de vetores com informa√ß√µes do suporte ao cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Criando o Chatbot RAG\n",
    "\n",
    "Agora, criamos um agente que busca respostas antes de responder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Local\\Temp\\ipykernel_18900\\405955736.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  resposta = qa.run(pergunta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do Chatbot:  O hor√°rio de atendimento do nosso suporte √© de segunda a sexta, das 9h √†s 18h.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama  # Import correto para Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "# Criando a cadeia de perguntas e respostas com recupera√ß√£o de contexto\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Fazendo uma pergunta ao chatbot\n",
    "pergunta = \"Qual o hor√°rio de atendimento?\"\n",
    "resposta = qa.run(pergunta)\n",
    "\n",
    "print(\"Resposta do Chatbot:\", resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclus√£o\n",
    "\n",
    "Qual LLM Escolher?\n",
    "\n",
    "![taela_llm](taela_llm.png)\n",
    "\n",
    "- ‚úÖ Se precisar de um chatbot local, v√° de Mistral 7B ou LLaMA 3.\n",
    "- ‚úÖ Se precisar de alta precis√£o, use GPT-4 Turbo ou Cohere API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
