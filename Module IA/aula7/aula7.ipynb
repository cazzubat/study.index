{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprofundando o RAG: Base de Conhecimento e Banco Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 1. Revis√£o R√°pida do RAG com LangChain\n",
    "\n",
    "#### O que √© um RAG?\n",
    "\n",
    "RAG = Retrieval-Augmented Generation\n",
    "\n",
    "Ele busca informa√ß√µes relevantes antes de gerar a resposta.\n",
    "\n",
    "Usa LLM + banco de vetores.\n",
    "\n",
    "#### Como funciona na pr√°tica:\n",
    "\n",
    "O usu√°rio envia uma pergunta.\n",
    "\n",
    "A pergunta √© vetorizada.\n",
    "\n",
    "O sistema busca vetores semelhantes na base.\n",
    "\n",
    "As informa√ß√µes encontradas s√£o repassadas para a LLM, que responde com contexto.\n",
    "\n",
    "#### Componentes principais:\n",
    "\n",
    "Embeddings (vetoriza√ß√£o): convertem texto em vetores num√©ricos.\n",
    "\n",
    "Vector Store (FAISS): armazena e busca os vetores.\n",
    "\n",
    "Retriever + LLM: fazem a m√°gica acontecer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Local\\Temp\\ipykernel_9060\\4192725594.py:13: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"mistral\")\n"
     ]
    }
   ],
   "source": [
    "# EXEMPLO\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Base de conhecimento\n",
    "documentos = [\n",
    "    Document(page_content=\"Nosso suporte funciona das 9h √†s 18h, de segunda a sexta.\"),\n",
    "    Document(page_content=\"O prazo de reembolso √© de at√© 7 dias √∫teis.\"),\n",
    "]\n",
    "\n",
    "# Vetoriza√ß√£o\n",
    "embedding_function = OllamaEmbeddings(model=\"mistral\")\n",
    "vectorstore = FAISS.from_documents(documentos, embedding_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå 2. Vetorizando Documentos Reais\n",
    "\n",
    "### Fontes de dados que podem ser usados:\n",
    "\n",
    "- Textos soltos em Python.\n",
    "\n",
    "- PDFs.\n",
    "\n",
    "- Arquivos .txt, .csv, .md.\n",
    "\n",
    "- FAQs e pol√≠ticas da empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 1: Vetorizando textos simples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "textos = \"\"\"\n",
    "A loja funciona de segunda a sexta-feira, das 8h √†s 17h.\n",
    "Para trocas ou devolu√ß√µes, √© necess√°rio entrar em contato em at√© 7 dias.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Quebrar o texto em blocos\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=100, chunk_overlap=20)\n",
    "blocos = splitter.create_documents([textos])\n",
    "\n",
    "# Vetorizando\n",
    "vectorstore = FAISS.from_documents(blocos, OllamaEmbeddings(model=\"mistral\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 2: Vetorizando um arquivo .txt ou .pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Carregar texto ou PDF\n",
    "loader = TextLoader(\"documentos/politicas.txt\")  # ou PyPDFLoader(\"documentos/manual.pdf\")\n",
    "documentos = loader.load()\n",
    "\n",
    "# Dividir e vetorizar\n",
    "blocos = splitter.split_documents(documentos)\n",
    "vectorstore = FAISS.from_documents(blocos, OllamaEmbeddings(model=\"mistral\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Agora temos uma base de conhecimento vetorizada a partir de arquivos reais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå 3. Buscando informa√ß√µes na base de vetores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A loja funciona de segunda a sexta-feira, das 8h √†s 17h.\n",
      "Para trocas ou devolu√ß√µes, √© necess√°rio entrar em contato em at√© 7 dias.\n"
     ]
    }
   ],
   "source": [
    "# Pergunta do usu√°rio\n",
    "pergunta = \"Qual o hor√°rio de atendimento?\"\n",
    "\n",
    "# Transformar a pergunta em vetor e buscar similaridade\n",
    "docs_relevantes = vectorstore.similarity_search(pergunta)\n",
    "\n",
    "for doc in docs_relevantes:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Tecnologias para Armazenamento Vetorial (Banco de Dados de Vetores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ O que √© um Banco Vetorial?\n",
    "\n",
    "√â um sistema de armazenamento e recupera√ß√£o que, em vez de fazer buscas por igualdade (=, LIKE), usa dist√¢ncia entre vetores para encontrar os itens mais semelhantes a um texto, imagem ou outro vetor.\n",
    "\n",
    "üß† √ötil em:\n",
    "\n",
    "- RAG (LangChain, LlamaIndex).\n",
    "\n",
    "- Busca sem√¢ntica.\n",
    "\n",
    "- Recomenda√ß√£o de conte√∫do.\n",
    "\n",
    "- Sistemas de IA que precisam entender o \"significado\" de algo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 1. FAISS (Facebook AI Similarity Search)\n",
    "\n",
    "- üí° Tipo: Biblioteca local para busca vetorial r√°pida.\n",
    "\n",
    "- üíª Armazenamento: Em mem√≥ria ou persist√™ncia simples (via pickle).\n",
    "\n",
    "- üèÉ‚Äç‚ôÄÔ∏è Velocidade: Extremamente r√°pido para uso local.\n",
    "\n",
    "- ‚ùå N√£o possui interface tipo SQL nativa.\n",
    "\n",
    "- ‚úÖ Ideal para: prot√≥tipos locais, projetos de pequeno/m√©dio porte.\n",
    "\n",
    "üì¶ Suportado por: LangChain, LlamaIndex, Haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(docs, OllamaEmbeddings(model=\"mistral\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 2. ChromaDB\n",
    "\n",
    "- üí° Tipo: Banco vetorial open-source, com API local e persist√™ncia em disco.\n",
    "\n",
    "- üì¶ Armazena vetores + metadados estruturados (como um SQL simplificado).\n",
    "\n",
    "- üß† Suporta filtros por metadados!\n",
    "\n",
    "- üåê Pode ser usado como servidor ou localmente.\n",
    "\n",
    "- ‚úÖ Ideal para: projetos persistentes, com m√∫ltiplos usu√°rios e filtros.\n",
    "\n",
    "üì¶ Suportado por: LangChain, LlamaIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, OllamaEmbeddings(model=\"mistral\"), persist_directory=\"./db\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 3. Weaviate\n",
    "\n",
    "- üí° Tipo: Banco de dados vetorial com estrutura sem√¢ntica tipo GraphQL.\n",
    "\n",
    "- üîç Suporte a queries estruturadas (por texto e metadados).\n",
    "\n",
    "- üß† Usa filtros e contexto no estilo SQL + AI.\n",
    "\n",
    "- **üåê Hosped√°vel via Docker, Cloud ou API.\n",
    "\n",
    "- ‚úÖ Ideal para: solu√ß√µes corporativas, sistemas em produ√ß√£o com m√∫ltiplos tipos de dados.\n",
    "\n",
    "üì¶ Suportado por: LangChain, LlamaIndex, diretamente via SDK Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 4. Pinecone\n",
    "\n",
    "- üí° Tipo: SaaS (servi√ßo em nuvem especializado em vetores).\n",
    "\n",
    "- üåê R√°pido, escal√°vel, com alta disponibilidade.\n",
    "\n",
    "- üìò Interface parecida com banco de dados, mas voltado para similaridade.\n",
    "\n",
    "- üß† Suporta metadados e filtros.\n",
    "\n",
    "- üí∞ Plano gratuito com limita√ß√µes.\n",
    "\n",
    "üì¶ Suportado por: LangChain, LlamaIndex, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "pinecone.init(api_key=\"SUA_CHAVE\", environment=\"us-west1-gcp\")\n",
    "index = pinecone.Index(\"meu_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 5. Milvus\n",
    "\n",
    "- üí° Tipo: Banco de dados vetorial open-source e altamente escal√°vel.\n",
    "\n",
    "- üîß Suporte a estrutura tipo SQL via MilvusQL.\n",
    "\n",
    "- üìä Pode armazenar bilh√µes de vetores com metadados.\n",
    "\n",
    "- ‚öôÔ∏è Requer mais setup (Docker, container).\n",
    "\n",
    "üì¶ Suportado por: LangChain, Zilliz Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© 6. Qdrant\n",
    "\n",
    "- üí° Tipo: Banco vetorial moderno, open-source e r√°pido.\n",
    "\n",
    "- üß† Excelente suporte a filtros por metadados.\n",
    "\n",
    "- üåê Acess√≠vel por API REST ou client Python.\n",
    "\n",
    "- ‚úÖ Interface simples + persist√™ncia.\n",
    "\n",
    "üì¶ Suportado por: LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tabeladbb](images/tabeladb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cenarios](images/cenarios.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos usar o ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ChromaDB √© um banco de dados vetorial open-source que armazena e busca documentos vetorizados com base em similaridade sem√¢ntica.\n",
    "\n",
    "üëâ Ele funciona como um ‚Äúbanco de dados de significados‚Äù, em vez de palavras exatas.\n",
    "\n",
    "Imagine que voc√™ tem uma FAQ com dezenas de perguntas/respostas, mas o usu√°rio escreve a d√∫vida com outras palavras.\n",
    "\n",
    "üí° Com o ChromaDB, voc√™ pode vetorizar essas perguntas e permitir que a IA encontre a resposta certa com base no significado, n√£o nas palavras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Passo a Passo: Como funciona o ChromaDB na pr√°tica\n",
    "\n",
    "#### ü•á Etapa 1: Instala√ß√£o\n",
    "```bash\n",
    "pip install chromadb langchain\n",
    "```\n",
    "\n",
    "\n",
    "#### ü•à Etapa 2: O que √© necess√°rio para usar o ChromaDB com LangChain?\n",
    "\n",
    "![cromaneed](images/cromaneed.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ü•â Etapa 3: Criando o Banco Vetorial com ChromaDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÅ Suponha que voc√™ tenha um documento de conhecimento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documentos = [\n",
    "    Document(page_content=\"O prazo para reembolso √© de at√© 7 dias √∫teis.\"),\n",
    "    Document(page_content=\"Nosso hor√°rio de atendimento √© de segunda a sexta, das 9h √†s 18h.\"),\n",
    "    Document(page_content=\"O suporte pode ser contatado via suporte@empresa.com.br\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî° Vetorizando os documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings  # ou OpenAIEmbeddings HuggingFaceEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Criando o VectorStore com Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documentos,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./meu_banco_chroma\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå O Chroma agora criou uma base vetorial persistente em disco!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß™ Etapa 4: Consultando o banco com uma pergunta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergunta de exemplo: \n",
    "\n",
    "```python\n",
    "pergunta = \"Como fa√ßo para pedir reembolso?\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar documentos similares:\n",
    "\n",
    "```python\n",
    "resultados = vectorstore.similarity_search(pergunta, k=2)\n",
    "\n",
    "for doc in resultados:\n",
    "    print(doc.page_content)\n",
    "\n",
    "```\n",
    "\n",
    "üí° O Chroma retorna os documentos mais parecidos em significado, n√£o em palavras!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O prazo para reembolso √© de at√© 7 dias √∫teis.\n",
      "Nosso hor√°rio de atendimento √© de segunda a sexta, das 9h √†s 18h.\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"Como fa√ßo para pedir reembolso?\"\n",
    "\n",
    "resultados = vectorstore.similarity_search(pergunta, k=2)\n",
    "\n",
    "for doc in resultados:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß† Etapa 5: Integrando com um modelo de IA (RAG)\n",
    "\n",
    "Agora que temos os documentos mais relevantes, vamos pedir a uma IA que gere uma resposta com base neles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Local\\Temp\\ipykernel_9060\\381921294.py:5: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mistral\", temperature=0)\n",
      "C:\\Users\\Eric\\AppData\\Local\\Temp\\ipykernel_9060\\381921294.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  resposta = qa.run(\"Como posso solicitar reembolso?\")\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Voc√™ pode solicitar o reembolso enviando um email para o endere√ßo de suporte da empresa, que √© suporte@empresa.com. Certifique-se de fazer isso dentro do prazo de 7 dias √∫teis ap√≥s a data em que foi realizado o pagamento.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama  # modelo local via Ollama\n",
    "\n",
    "# Inicializa o modelo local Mistral via Ollama\n",
    "llm = Ollama(model=\"mistral\", temperature=0)\n",
    "\n",
    "# Cria a cadeia de perguntas e respostas\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Faz a pergunta\n",
    "resposta = qa.run(\"Como posso solicitar reembolso?\")\n",
    "print(resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß± Resumo de Componentes Chave do ChromaDB\n",
    "\n",
    "![resumo](images/resumo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como fazer para inserir documentos para serem vetorizados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel transformar arquivos como PDF, Word, TXT e at√© HTML em vetores para o ChromaDB, e voc√™ pode fazer isso de forma manual via c√≥digo ou usando loaders autom√°ticos do LangChain.\n",
    "\n",
    "LangChain tem loaders prontos para arquivos como:\n",
    "\n",
    "![loaders](images/loaders.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF ‚Üí vetores no Chroma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Carregando o PDF\n",
    "loader = PyPDFLoader(\"politica_reembolso.pdf\")\n",
    "documentos = loader.load()\n",
    "\n",
    "# 2. Separando o conte√∫do em blocos pequenos (chunking)\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "blocos = splitter.split_documents(documentos)\n",
    "\n",
    "# 3. Vetorizando e salvando no Chroma\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documentos=blocos,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./meu_banco_vetorial\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Comparando: Inserir via C√≥digo vs Arquivos Carregados\n",
    "\n",
    "![comparativo](images/comparativo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö¶ Quando usar cada abordagem?\n",
    "\n",
    "![comparativo2](images/comparativo2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Dica Extra: Combinando os dois m√©todos\n",
    "\n",
    "Voc√™ pode:\n",
    "\n",
    "- Criar uma base com alguns textos no c√≥digo.\n",
    "- Acrescentar arquivos reais (PDF, CSV, etc).\n",
    "- Misturar tudo antes de vetorizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_combinados = textos_do_codigo + pdfs_carregados\n",
    "vectorstore = Chroma.from_documents(documentos_combinados, OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos testar a vetoriza√ß√£o de coumentos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RAG com ChromaDB\n",
    "\n",
    "üìÑ PDF fict√≠cio de uma pol√≠tica de reembolso da empresa \"Infinity Tech\".\n",
    "\n",
    "üß† Script Python que:\n",
    "\n",
    "Carrega o PDF.\n",
    "\n",
    "Divide em blocos de texto (chunking).\n",
    "\n",
    "Vetoriza os blocos com embeddings.\n",
    "\n",
    "Armazena tudo no ChromaDB.\n",
    "\n",
    "üß™ Atividade pr√°tica para os alunos, com perguntas para testar o RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Script Python ‚Äì Carregando e Vetorizando o PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base vetorial criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Carregar o PDF\n",
    "loader = PyPDFLoader(\"politica_reembolso_infinitytech.pdf\")\n",
    "documentos = loader.load()\n",
    "\n",
    "# 2. Dividir em blocos (chunking)\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "blocos = splitter.split_documents(documentos)\n",
    "\n",
    "# 3. Vetorizar com OpenAI embeddings e salvar no ChromaDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=blocos,\n",
    "    embedding=OllamaEmbeddings(model=\"mistral\"),  # ou HuggingFaceEmbeddings()\n",
    "    persist_directory=\"./chroma_db_infinity\"\n",
    ")\n",
    "\n",
    "print(\"Base vetorial criada com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Script de Consulta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Resposta:  Para pedir uma segunda via do boleto, voc√™ precisa entrar em contato com o nosso suporte de atendimento. Voc√™ pode enviar um e-mail para [suporte@infinitytech.com](mailto:suporte@infinitytech.com) com a solicita√ß√£o espec√≠fica, incluindo o n√∫mero do pedido. O time de atendimento ser√° feliz em ajudar voc√™.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "# 7. Consulta\n",
    "pergunta = \"Como posso pedir a segunda via do boleto?\"\n",
    "resposta = qa.invoke({\n",
    "    \"question\": pergunta,\n",
    "    \"chat_history\":[]\n",
    "})\n",
    "print(\"üß† Resposta:\", resposta[\"answer\"])\n",
    "\n",
    "\n",
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     llm=ChatOpenAI(openai_api_key=\"SUA_API_KEY\"),\n",
    "#     retriever=vectorstore.as_retriever()\n",
    "# )\n",
    "\n",
    "# pergunta = \"Como posso pedir um reembolso?\"\n",
    "# resposta = qa.run(pergunta)\n",
    "# print(\"Resposta do chatbot:\", resposta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como estruturar um PDF ideal para uso em RAG (Chatbot IA)\n",
    "\n",
    "Uma das principais dores de quem trabalha com RAG √© receber PDFs mal formatados, com muito ru√≠do ou estrutura desorganizada, o que prejudica a vetoriza√ß√£o e a recupera√ß√£o de informa√ß√µes.\n",
    "\n",
    "Voc√™ pode resolver isso criando um modelo-padr√£o de estrutura de PDF, com boas pr√°ticas e instru√ß√µes claras para o cliente preencher. Vamos fazer isso agora!\n",
    "\n",
    "üìå Objetivo:\n",
    "\n",
    "Orientar seu cliente a montar um PDF limpo, bem dividido e estruturado, que facilite a vetoriza√ß√£o com ferramentas como LangChain + ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Modelo de Estrutura Padr√£o do PDF\n",
    "\n",
    "#### 1 Use T√≠tulos Claros e Numerados\n",
    "Evite blocos gigantes de texto. Use se√ß√µes com numera√ß√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "1. SOBRE A EMPRESA\n",
    "A Infinity Tech √© uma empresa especializada em solu√ß√µes digitais...\n",
    "\n",
    "2. POL√çTICA DE REEMBOLSO\n",
    "2.1 O cliente tem at√© 7 dias √∫teis para solicitar reembolso.\n",
    "2.2 O reembolso ser√° feito via o mesmo m√©todo de pagamento.\n",
    "\n",
    "3. CONTATO\n",
    "3.1 E-mail: suporte@infinitytech.com.br\n",
    "3.2 Telefone: (11) 4000-1234\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 N√£o misture temas\n",
    "\n",
    "‚úÖ Use 1 tema por par√°grafo.\n",
    "‚ùå N√£o agrupe v√°rios assuntos no mesmo bloco.\n",
    "Isso ajuda o RAG a dividir corretamente os chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Evite elementos gr√°ficos\n",
    "\n",
    "‚ùå Tabelas com muitas colunas.\n",
    "‚ùå Imagens com informa√ß√µes importantes.\n",
    "‚úÖ Texto plano e estruturado √© mais confi√°vel para extra√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Use frases completas\n",
    "\n",
    "Evite frases curtas tipo bullet points soltos.\n",
    "\n",
    "```bash\n",
    "‚úÖ O cliente deve enviar o comprovante por e-mail para dar in√≠cio ao processo de troca.\n",
    "‚ùå Enviar comprovante. E-mail. Troca.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 D√™ prefer√™ncia a formatos edit√°veis\n",
    "\n",
    "Se poss√≠vel, pe√ßa o conte√∫do em .docx ou .txt para facilitar o pr√©-processamento.\n",
    "Voc√™ pode converter para PDF posteriormente com controle.\n",
    "\n",
    "\n",
    "üìù Texto de instru√ß√£o para enviar ao cliente\n",
    "\n",
    "```bash\n",
    "Prezado(a),\n",
    "Para que possamos integrar suas informa√ß√µes ao nosso sistema de IA com maior precis√£o e efici√™ncia, solicitamos que o documento enviado atenda ao seguinte modelo:\n",
    "\n",
    "Use t√≠tulos e subt√≠tulos numerados para cada tema.\n",
    "\n",
    "Mantenha os textos em blocos coerentes, com um t√≥pico por par√°grafo.\n",
    "\n",
    "Evite gr√°ficos ou tabelas complexas.\n",
    "\n",
    "Use frases completas, evite anota√ß√µes soltas.\n",
    "\n",
    "Envie preferencialmente em .docx, .txt ou .pdf gerado a partir de texto puro (n√£o escaneado).\n",
    "\n",
    "Voc√™ pode seguir o modelo que enviamos como base:\n",
    "(anexe o PDF de exemplo que posso gerar para voc√™ agora)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
